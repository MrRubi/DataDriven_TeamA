---
title: "Analysis of Honeypots activity"
output:
  html_document: default
  pdf_document: default
  word_document: default
date: "14 de diciembre de 2017"
---

#Analysis of Honeypots activity

EQUIPO A. Práctica módulo Data Driven Security, máster en cybersecurity management edición 2017-2018. UPC SCHOOL

Para esta práctica hemos obtenido datos del tráfico de 9 Honeypots del 2013, distribuidos globalmente, entre Marzo y Septiembre. Entre los datos facilitados, encontramos información como el timestamp, el host "atacado",el origen del ataque (tanto localidad como la dirección ip), etc.

Las preguntas que nos hemos planteado son las siguientes:

1. Determinar cual es el Honeypot más atacado de todos los desplegados, y en base a ese resultado, ver de dónde provienen los ataques
2. ¿ Cuáles son los protocolos y puertos más usados?
3. ¿Existe alguna relación entre la geolocalización del honeypot y el puerto atacado?

Integrantes del Equipo A:
  
- Ángel Rubiño Fernández [MR. T]
- Álex Gonzalo Rodríguez [Hannibal]
- José Raúl Jiménez Lama [Fénix]
- Marc Pallejà Mairena [Murdok]

##Carga de los datos y filtrado de informacion

En esta primera parte pretendemos cargar el CSV, analizar los datos, limpiar, y quedarnos con un dataframe con el que poder trabajar y resolver nuestras cuestiones.

```{r prepare_working_directory, echo = FALSE}
if (!file.exists("laboratory")) {
  dir.create("laboratory")
}  
```

```{r setoptions, echo=FALSE}
knitr::opts_chunk$set(echo = FALSE)
knitr::opts_knit$set(root.dir = "./laboratory")
```

```{r download_dataset}
  if(!file.exists("marx-geo.tar.gz")){
  fileUrl <- "http://datadrivensecurity.info/blog/data/2014/01/marx-geo.tar.gz"
  download.file(url = fileUrl, destfile = "marx-geo.tar.gz")
  untar("marx-geo.tar.gz")
  }
```

```{r load_csv, cache = TRUE}
Complete_Dataset <- read.csv("./marx-geo.csv",header = TRUE, check.names = TRUE)
```

Una vez cargado, podemos ver que el dataset dispone de 15 columnas y 451.664 filas (Variables y Observaciónes respectivamente)

```{r dim}
dim(Complete_Dataset)
```

Las variables en cuestion se pueden observar con el siguiente comando:


```{r nombre_variables}
names(Complete_Dataset)
```

- **datetime:** Tiempo en el que tuvo lugar el ataque en formato dd/mm/yyyy hh/mm/ss

- **host:** Identificador del honeypot atacado

- **src:** Segun la fuente de los datos, representa la direccion ip origen, aunque desconocemos el formato utilizado

- **proto:** Protocolo de comunicacion usado (TCP,UDP,ICMP)

- **type:** Tipo de mensaje ICMP

- **spt:** Puerto origen del ataque

- **dpt:** Puerto destino del ataque

- **srcstr:** Similar a src, pero en formato tradicional

- **cc:** Abreviacion del pais desde el que se realiza el ataque

- **country:** Pais desde el que se realiza el ataque

- **locale:** Poblacion desde la que se realiza el ataque

- **localeabbr:** Abreviacion de la poblacion desde la que se realiza el ataque

- **postalcode:** Codigo postal de la localidad desde donde se realiza el ataque

- **latitude:** Coordenada latitud del origen del ataque

- **longitude:** Coordenada longitud del origen del ataque

Un primer acercamiento, podría ser observar las mil primeras entradas del dataset, para poder hacernos una idea de la información y si se han cargado bien.

```{r primeras_muestras}
DataSet_Sample <- head(Complete_Dataset, n = 10000)
summary(DataSet_Sample)
```

Despues de observar el dataset reducido, algunas de las conclusiones obtenidas son:  

1. Hay un número elevado de obsevaciones donde la variable *type* tiene valor NA (en principio tienen que ser las observaciones donde el protocolo utilizado es distinto de ICMP). Del mismo modo, aunque en menor medida, encontramos el mismo comportamiento para las variables *dpt* y *spt*, suponemos que debe ser para los casos que el protocolo utilizado es distinto de TCP o UDP.


2. Las variables *Locale*, *localeabbr*, *postal code*, *latitude* y *longitude* en determinadas entradas estan vacias. A priori suponemos que se da en las observaciones donde no se ha conseguido determinar la localidad exacta desde donde se realiza el ataque, tan solo el pais.


Vamos a verificar nuestras sospechas. Empecemos por el campo *type*, que tiene muchas observaciones a NA. 

Vamos a crear un dataset con las observaciones donde *type* sea diferente de NA y analizarlo manualmente.

```{r check_na_subset}
DataSet_na_type <- Complete_Dataset[!is.na(Complete_Dataset$type),]
unique(DataSet_na_type$proto)
```


En todos los casos, el protocolo es ICMP, por lo que type debe referirse al tipo de comando ICMP enviado.

Como hemos visto anteriormente, las variables *Locale*, *localeabbr*, *postal code*, *latitude* y *longitud* tienen observaciones a NA. Antes de dedicar esfuerzos a analizar dichas entradas, hemos de tener en cuenta que para resolver las preguntas de la práctica, necesitamos saber el pais, no queremos profundizar a nivel de localidad, por lo que las variables mencionadas no formaran parte del dataset final con el que vamos a trabajar, y, por lo tanto, vamos a eliminarlos de nuestro dataframe.


Antes de crear el subset de datos con el que vamos a trabajar para resolver las preguntas, hay otras observaciones que también deberemos filtrar, concretamente hablamos de:

- src: No entendemos el formato de esta variable
- srcstr: No necesitamos saber la direccion ip origen, ya disponemos de la variable country
- cc: De forma análoga a lo mencionado en el punto anterior, no necesitamos esta variable

```{r dataframe_filtered}
subset.columns <- c("datetime","host","proto","type","spt","dpt", "country")
DataSet_filtered <- Complete_Dataset[subset.columns]
summary(DataSet_filtered)
```

Una vez ya tenemos la información que queremos, hemos de verificar que no hay ningún dato erroneo entre las observaciones de nuestra poblacion. Para ello, miraremos con unique cuales son los posibles valores que tiene cada variable y comprobaremos si alguno de ellos es NA. Para  aquellos casos en los que haya muchos valores distintos crearemos un dataframe donde guardaremos las observaciones cuyo valor de variable sea NA y comprobaremos el tamaño de dicho dataframe.

```{r check_datetime_na, results='hide', echo= TRUE}
unique(DataSet_filtered$datetime)
aux_datetime <- DataSet_filtered[is.na(DataSet_filtered$datetime),]
total_na <- nrow(aux_datetime)
```

- variable **datetime**: `r total_na` NA

```{r check_host_na, results='hide', echo= TRUE}
unique(DataSet_filtered$host)
aux_host <- DataSet_filtered[is.na(DataSet_filtered$host),]
total_na <- nrow(aux_host)
```

- variable **host**: `r total_na` NA

```{r check_proto_na, results='hide', echo= TRUE}
unique(DataSet_filtered$proto)
aux_proto <- DataSet_filtered[is.na(DataSet_filtered$proto),]
total_na <- nrow(aux_proto)
```
- variable **proto**: `r total_na` NA

```{r check_type_na, results='hide', echo= TRUE}
unique(DataSet_filtered$type)
aux_type <- DataSet_filtered[is.na(DataSet_filtered$type),]
total_na <- nrow(aux_type)
not_icmp_protocols <- unique(aux_type$proto)
```
- variable **type**: `r total_na` que todos estan relacionados con aquellos protocolos que no son **ICMP** ya que no tienen valor para esta variable: `r not_icmp_protocols`

```{r check_spt_na, results='hide', echo= TRUE}
unique(DataSet_filtered$spt)
aux_spt <- DataSet_filtered[is.na(DataSet_filtered$spt),]
total_na <- nrow(aux_spt)
all_protocols_affected <- unique(aux_spt$proto)
```

- variable **spt**: `r total_na` NA que en este caso afectan al/los protocolos: `r all_protocols_affected`

```{r check_dpt_na, results='hide', echo= TRUE}
unique(DataSet_filtered$dpt)
aux_dpt <- DataSet_filtered[is.na(DataSet_filtered$dpt),]
total_na <- nrow(aux_dpt)
all_protocols_affected <- unique(aux_dpt$proto)
```

- variable **dpt**: `r total_na` NA que en este caso afectan al/los los protocolos: `r all_protocols_affected`

```{r check__na, results='hide', echo= TRUE}
unique(DataSet_filtered$country)
aux_country <- DataSet_filtered[is.na(DataSet_filtered$country),]
total_na <- nrow(aux_country)
DataSet_filtered <- DataSet_filtered[-which(DataSet_filtered$country == ""), ]
```

- variable **country**: `r total_na` NA

Llegados a este punto, en el dataframe *DataSet_filtered* disponemos de toda la información necesaria y filtrada para poder empezar a responder a nuestras preguntas.

#Honeypot mas atacado

El dataset encontrado dispone de datos sobre 9 honeypots distintos.

- groucho-oregon
- groucho-us-east
- groucho-singapore
- groucho-tokyo
- groucho-sa
- zeppo-norcal     
- groucho-norcal
- groucho-eu
- groucho-sydney  


En un primer paso de analisis, vamos a comprobar el trafico de cada honeypot e intentar determinar cual ha sido el mas atacado.

```{r includes_1,results='hide',echo= FALSE}
source("../utils.R")
library(ggplot2)
suppressMessages(library(dplyr))
```

```{r mostattacked,echo= TRUE}

DataSet_filtered$attacks <- c(1)  # they all occur once right now
hosts <- aggregate(attacks ~ host, data = DataSet_filtered, FUN = sum)

#reorder funtion is used to print attacks in ascending order
attacksByHoneypot.graphic <- ggplot(hosts, aes(x = reorder(host, attacks), y=attacks, fill = host))
attacksByHoneypot.graphic <- attacksByHoneypot.graphic + geom_bar(stat = "identity", width = 0.5)
attacksByHoneypot.graphic <- attacksByHoneypot.graphic + labs(y = "Attacks", x = "Honeypots", title = "Received attacks by honeypot")
attacksByHoneypot.graphic <- graphicCustomization(attacksByHoneypot.graphic)
print(attacksByHoneypot.graphic)
```


Los honeypots con mas ataques son en orden ascendente Singapur, Oregon y Tokyo.  
Estos resultados entran dentro de lo esperado, tanto Tokyo como Singapur se encuentran en el contiente asiatico, al igual que china, pais con una gran reputación en cuanto a la realizacion de ciberataques. Por ultimo, Oregon forma parte de Estados Unidos, uno de los paises mas atacado a nivel informatico del mundo.

Sabiendo los paises mas atacados, vamos a ver los tres paises que mas atacan a cada honeypot.

```{r mostattacked_top3,echo= TRUE}
#group by host and country to know which country has performed more attacks adding the attacks entries and getting the top 3
mostAttackedHostsByCountry <- DataSet_filtered %>% group_by(host, country) %>% summarise(attacks = sum(attacks)) %>% top_n(3, attacks)

#print graphic to see the results
dodge <- position_dodge(width = 0.9)
attacksLocation.graphic <- ggplot(mostAttackedHostsByCountry, aes(x = host, y = attacks, fill = country)) 
attacksLocation.graphic <- attacksLocation.graphic + geom_bar(stat = "identity", position = position_dodge())
attacksLocation.graphic <- attacksLocation.graphic + labs(y = "Attacks", x = "Honeypots", title = "Top 3 attacks location")

bDelete_x_AxisNames = FALSE
attacksLocation.graphic <- graphicCustomization(attacksLocation.graphic, FALSE)
print(attacksLocation.graphic)
```


Los dos primeros paises atacantes para cada honeypot son comunes, China y Estados Unidos.Como ya hemos comentado anteriormente, entra dentro de lo esperado, a parte de ser dos paises con un nivel de poblacion elevado, tambien tiene una gran reputacion en cuanto a su actividad cibercriminal.

Para acabar de hacernos una idea de mapa de ataques, vamos a observar el origen de los ataques en un mapa

```{r libraries, result='hide', echo= FALSE}
library("ggmap")
library(ggplot2)
```

```{r mapas,echo= TRUE}
#Nos quedamos con las columnas que nos hagan falta, en este caso queremos representar de donde vienen los ataques
#y nos centraremos solo en la longitud y latitud para representar de donde provienen, para ello seleccionaremos estas 2 columnas
#y las pondremos en la variable "localizacion"
coordenadas <- c("latitude", "longitude")
localizacion <- Complete_Dataset[coordenadas]

#Filtramos los NA omitiéndolos y luego verificamos si siguen apareciendo en nuestros datos
localizacion <- na.omit(localizacion)
nrow(localizacion[is.na(localizacion$latitude),])

#La latitud solo puede tener valores a 90 (según la escala de Microsoft https://msdn.microsoft.com/en-us/library/aa578799.aspx)
#Por lo tanto, elegiremos este valor, para descartar valores mucho mayores a esta escala que hagan que no se representen
#Correctamente los ataques en el mapa del mundo
localizacion <- localizacion[localizacion$latitude<90,]

#Guardamos las columnas de longitud y latitud una vez filtradas y procesadas, en las variables "longitud" y "latitud" respectivamente
longitud <- localizacion$longitude
latitud <- localizacion$latitude

#Realizamos la función mapWorld a través de ggplot, con los parámetros necesarios para crear el mapa, y lo guardaremos en la variable mp 
mp <- NULL
mapWorld <- borders("world", colour="gray50", fill="gray50") # create a layer of borders
mp <- ggplot() +   mapWorld

#Mostramos en el mapa, nuestras longitudes y latitudes representándolas en el mapa como puntos naranjas con transparencias
mp <- mp+ geom_point(aes(x=longitud, y=latitud) ,color=rgb(1,0.65,0,0.2), size=0.5) 
mp
```

Un vez visto el volumen de ataques y el origen, vamos a realizar un análisis en profundidad de como se han llevado a cabo los ataques, es decir, que protocolos y puertos han sido los más usados.

Primero, empezaremos analizando los protocolos de transporte más usados (TCP, UDP o ICMP) para los ataques a honeypots.

```{r ptransporte, echo= TRUE}
#filter protocol ('proto') and destination port ('dpt') columns 
protocolAndPortDataSet <- DataSet_filtered[c("proto", "dpt")]

#perform a count by protocol to know the most used
protocol.aggregate <- protocolAndPortDataSet %>% count(proto, sort = T)

#print graphic to see the results
protocol.graphic <- ggplot(protocol.aggregate, aes(x = proto, y = n, fill = proto))
protocol.graphic <- protocol.graphic + geom_bar(stat = "identity", width = 0.5)
protocol.graphic <- protocol.graphic + labs(y = "Used times", x = "Protocols", title = "Most transport protocol used")
protocol.graphic <- graphicCustomization(protocol.graphic)
print(protocol.graphic)
```

Una mejor manera de interpretar los resultados es a través de un gráfico circular con procentajes asociados a los protocolos de transporte, como el siguiente:

```{r quesito, echo= TRUE}
#Another interesting and useful way of watching the previous graphic is through a pie chart
pct <- round(protocol.aggregate$n/sum(protocol.aggregate$n)*100)
lbls <- paste(protocol.aggregate$proto, pct) # add percents to labels
lbls <- paste(lbls,"%",sep="") # ad % to labels 
pie(protocol.aggregate$n,labels = lbls,col=rainbow(length(lbls)),
    main="Pie Chart of most used communication protocols") 
```

